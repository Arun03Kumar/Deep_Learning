{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0yrDVM0R7Aw"
      },
      "outputs": [],
      "source": [
        "# Installing the requirements\n",
        "print('Installing Requirements... ',end='')\n",
        "!pip install lightning\n",
        "!pip install wandb\n",
        "print('Done')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVhCdZrhm1VM"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbjpBLpc8sno"
      },
      "outputs": [],
      "source": [
        "# Importing Libraries\n",
        "print('Importing Libraries... ',end='')\n",
        "import os\n",
        "import math\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import torchaudio\n",
        "import zipfile\n",
        "from torchaudio.transforms import Resample\n",
        "import IPython.display as ipd\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import pytorch_lightning as pl\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import seaborn as sns\n",
        "import wandb\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import torch.nn.functional as F\n",
        "from torchmetrics import Accuracy, ConfusionMatrix, AUROC\n",
        "from torchmetrics.classification import MulticlassF1Score, MulticlassAUROC\n",
        "print('Done')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYS2KYTZSOFP"
      },
      "outputs": [],
      "source": [
        "# Extract data\n",
        "with zipfile.ZipFile(\"/content/drive/MyDrive/Archive.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VttdfD-p8gfL"
      },
      "outputs": [],
      "source": [
        "# Loading dataset\n",
        "path = Path('/content')\n",
        "df = pd.read_csv('/content/meta/esc50.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_SDQQJfNK-4"
      },
      "outputs": [],
      "source": [
        "# Getting list of raw audio files\n",
        "wavs = list(path.glob('audio/*'))  # List all audio files in the 'audio' directory using pathlib.Path.glob\n",
        "\n",
        "# Visualizing data\n",
        "waveform, sample_rate = torchaudio.load(wavs[0])  # Load the waveform and sample rate of the first audio file using torchaudio\n",
        "\n",
        "print(\"Shape of waveform: {}\".format(waveform.size()))  # Print the shape of the waveform tensor\n",
        "print(\"Sample rate of waveform: {}\".format(sample_rate))  # Print the sample rate of the audio file\n",
        "\n",
        "# Plot the waveform using matplotlib\n",
        "plt.figure()\n",
        "plt.plot(waveform.t().numpy())  # Transpose and convert the waveform tensor to a NumPy array for plotting\n",
        "\n",
        "# Display the audio using IPython.display.Audio\n",
        "ipd.Audio(waveform, rate=sample_rate)  # Create an interactive audio player for the loaded waveform\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3X0MFpA_RNKI"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataset, **kwargs):\n",
        "        # Initialize CustomDataset object with relevant parameters\n",
        "        # dataset: \"train\", \"val\", or \"test\"\n",
        "        # kwargs: Additional parameters like data directory, dataframe, folds, etc.\n",
        "\n",
        "        # Extract parameters from kwargs\n",
        "        self.data_directory = kwargs[\"data_directory\"]\n",
        "        self.data_frame = kwargs[\"data_frame\"]\n",
        "        self.validation_fold = kwargs[\"validation_fold\"]\n",
        "        self.testing_fold = kwargs[\"testing_fold\"]\n",
        "        self.esc_10_flag = kwargs[\"esc_10_flag\"]\n",
        "        self.file_column = kwargs[\"file_column\"]\n",
        "        self.label_column = kwargs[\"label_column\"]\n",
        "        self.sampling_rate = kwargs[\"sampling_rate\"]\n",
        "        self.new_sampling_rate = kwargs[\"new_sampling_rate\"]\n",
        "        self.sample_length_seconds = kwargs[\"sample_length_seconds\"]\n",
        "\n",
        "        # print(self.data_frame.shape)\n",
        "\n",
        "        # Filter dataframe based on esc_10_flag and data_type\n",
        "        if self.esc_10_flag:\n",
        "            self.data_frame = self.data_frame.loc[self.data_frame['esc10'] == True]\n",
        "        # print(self.data_frame.shape)\n",
        "\n",
        "        if dataset == \"train\":\n",
        "            self.data_frame = self.data_frame.loc[\n",
        "                (self.data_frame['fold'] != self.validation_fold) & (self.data_frame['fold'] != self.testing_fold)]\n",
        "        elif dataset == \"val\":\n",
        "            self.data_frame = self.data_frame.loc[self.data_frame['fold'] == self.validation_fold]\n",
        "        elif dataset == \"test\":\n",
        "            self.data_frame = self.data_frame.loc[self.data_frame['fold'] == self.testing_fold]\n",
        "\n",
        "        # Get unique categories from the filtered dataframe\n",
        "        self.categories = sorted(self.data_frame[self.label_column].unique())\n",
        "        label_counts = self.data_frame[self.label_column].value_counts()\n",
        "        # print(label_counts)\n",
        "        # print(self.categories)\n",
        "\n",
        "        # Initialize lists to hold file names, labels, and folder numbers\n",
        "        self.file_names = []\n",
        "        self.labels = []\n",
        "\n",
        "        # Initialize dictionaries for category-to-index and index-to-category mapping\n",
        "        self.category_to_index = {}\n",
        "        self.index_to_category = {}\n",
        "\n",
        "        for i, category in enumerate(self.categories):\n",
        "            self.category_to_index[category] = i\n",
        "            self.index_to_category[i] = category\n",
        "\n",
        "        # if(True):\n",
        "        #   print(self.category_to_index)\n",
        "        #   print(self.index_to_category)\n",
        "\n",
        "        # Populate file names and labels lists by iterating through the dataframe\n",
        "        for ind in tqdm(range(len(self.data_frame))):\n",
        "            row = self.data_frame.iloc[ind]\n",
        "            # print(row)\n",
        "            file_path = self.data_directory / \"audio\" / row[self.file_column]\n",
        "            # print(file_path)\n",
        "            self.file_names.append(file_path)\n",
        "            self.labels.append(self.category_to_index[row[self.label_column]])\n",
        "\n",
        "        # print(self.file_names)\n",
        "        # print(self.labels)\n",
        "\n",
        "        # if(dataset == \"train\"):\n",
        "        #   for i in range(len(self.file_names)):\n",
        "        #     print(self.file_names[i], self.labels[i])\n",
        "\n",
        "        self.resampler = torchaudio.transforms.Resample(self.sampling_rate, self.new_sampling_rate)\n",
        "\n",
        "        # Window size for rolling window sample splits (unfold method)\n",
        "        if self.sample_length_seconds == 2:\n",
        "            self.window_size = self.new_sampling_rate * 2\n",
        "            self.step_size = int(self.new_sampling_rate * 0.75)\n",
        "        else:\n",
        "            self.window_size = self.new_sampling_rate\n",
        "            self.step_size = int(self.new_sampling_rate * 0.5)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Split audio files with overlap, pass as stacked tensors tensor with a single label\n",
        "        path = self.file_names[index]\n",
        "        audio_file = torchaudio.load(path, format=None, normalize=True)\n",
        "        audio_tensor = self.resampler(audio_file[0])\n",
        "        L = audio_tensor.size(1)\n",
        "        # print(L)\n",
        "        splits = audio_tensor.unfold(1, self.window_size, self.step_size)\n",
        "        # print(splits.shape)\n",
        "        samples = splits.permute(1, 0, 2)\n",
        "        return samples, self.labels[index], path\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2JUJdPTRjix"
      },
      "outputs": [],
      "source": [
        "class CustomDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, **kwargs):\n",
        "        # Initialize the CustomDataModule with batch size, number of workers, and other parameters\n",
        "        super().__init__()\n",
        "        self.batch_size = kwargs[\"batch_size\"]\n",
        "        self.num_workers = kwargs[\"num_workers\"]\n",
        "        self.data_module_kwargs = kwargs\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        # Define datasets for training, validation, and testing during Lightning setup\n",
        "\n",
        "        # If in 'fit' or None stage, create training and validation datasets\n",
        "        if stage == 'fit' or stage is None:\n",
        "            self.training_dataset = CustomDataset(dataset=\"train\", **self.data_module_kwargs)\n",
        "            self.validation_dataset = CustomDataset(dataset=\"val\", **self.data_module_kwargs)\n",
        "\n",
        "        # If in 'test' or None stage, create testing dataset\n",
        "        if stage == 'test' or stage is None:\n",
        "            self.testing_dataset = CustomDataset(dataset=\"test\", **self.data_module_kwargs)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        # Return DataLoader for training dataset\n",
        "        return DataLoader(self.training_dataset,\n",
        "                          batch_size=self.batch_size,\n",
        "                          shuffle=True,\n",
        "                          collate_fn=self.collate_function,\n",
        "                          num_workers=self.num_workers)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        # Return DataLoader for validation dataset\n",
        "        return DataLoader(self.validation_dataset,\n",
        "                          batch_size=self.batch_size,\n",
        "                          shuffle=False,\n",
        "                          collate_fn=self.collate_function,\n",
        "                          num_workers=self.num_workers)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        # Return DataLoader for testing dataset\n",
        "        return DataLoader(self.testing_dataset,\n",
        "                          batch_size=self.batch_size,\n",
        "                          shuffle=False,\n",
        "                          collate_fn=self.collate_function,\n",
        "                          num_workers=self.num_workers)\n",
        "\n",
        "    def collate_function(self, data):\n",
        "        \"\"\"\n",
        "        Collate function to process a batch of examples and labels.\n",
        "\n",
        "        Args:\n",
        "            data: a tuple of 2 tuples with (example, label) where\n",
        "                example are the split 1 second sub-frame audio tensors per file\n",
        "                label = the label\n",
        "\n",
        "        Returns:\n",
        "            A list containing examples (concatenated tensors) and labels (flattened tensor).\n",
        "        \"\"\"\n",
        "        # examples, labels = zip(*data)\n",
        "        # examples = torch.cat(examples)\n",
        "        # labels = torch.flatten(torch.tensor(labels))\n",
        "        # # examples = examples[:8]\n",
        "\n",
        "        # return [examples, labels]\n",
        "\n",
        "        examples, labels, path = zip(*data)\n",
        "        #print(path, labels)\n",
        "        # print(labels)\n",
        "        batch_size = len(examples)  # Get the actual batch size\n",
        "\n",
        "        # Duplicate labels to match the number of segments per batch\n",
        "        duplicated_labels = []\n",
        "        for l in labels:\n",
        "            duplicated_labels.extend([l] * len(examples[0]))  # Assuming all examples have the same length\n",
        "\n",
        "        # Concatenate examples along the batch dimension\n",
        "        examples_batch = torch.cat(examples)\n",
        "\n",
        "        # Flatten duplicated labels\n",
        "        labels_batch = torch.tensor(duplicated_labels)\n",
        "\n",
        "        return examples_batch, labels_batch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Irm0dFPaS1JR"
      },
      "outputs": [],
      "source": [
        "def kfold(valid_samp):\n",
        "  test_samp = 1 #\"\"\" Do not change this!! \"\"\"\n",
        "  valid_samp = valid_samp # Use any value ranging from 2 to 5 for k-fold validation (valid_fold)\n",
        "  batch_size = 32 # Free to change\n",
        "  num_workers = 4 # Free to change\n",
        "  custom_data_module = CustomDataModule(batch_size=batch_size,\n",
        "                                        num_workers=num_workers,\n",
        "                                        data_directory=path,\n",
        "                                        data_frame=df,\n",
        "                                        validation_fold=valid_samp,\n",
        "                                        testing_fold=test_samp,  # set to 0 for no test set\n",
        "                                        esc_10_flag=True,\n",
        "                                        file_column='filename',\n",
        "                                        label_column='category',\n",
        "                                        sampling_rate=44100,\n",
        "                                        new_sampling_rate=16000,  # new sample rate for input\n",
        "                                        sample_length_seconds=1  # new length of input in seconds\n",
        "                                        )\n",
        "\n",
        "  custom_data_module.setup()\n",
        "  return custom_data_module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EehOMSiPs-_"
      },
      "outputs": [],
      "source": [
        "torch.cuda.device_count()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuDSuSCYbHb8"
      },
      "outputs": [],
      "source": [
        "# for batch_data, batch_labels in custom_data_module.train_dataloader():\n",
        "#     print(f\"Input shape: {batch_data.shape}, Labels shape: {batch_labels.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d99m0N3umD_x"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class OneD_CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(OneD_CNN, self).__init__()\n",
        "\n",
        "        self.hiddenLayers = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=1, out_channels=8, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
        "            nn.BatchNorm1d(8),\n",
        "            # nn.Dropout(0.5),\n",
        "\n",
        "            nn.Conv1d(in_channels=8, out_channels=16, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
        "            nn.BatchNorm1d(16),\n",
        "            # nn.Dropout(0.5),\n",
        "\n",
        "            nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
        "            nn.BatchNorm1d(32),\n",
        "            # nn.Dropout(0.5),\n",
        "\n",
        "            nn.Conv1d(in_channels=32, out_channels=16, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
        "            nn.BatchNorm1d(16),\n",
        "            # nn.Dropout(0.5),\n",
        "\n",
        "            nn.Conv1d(in_channels=16, out_channels=8, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
        "            nn.BatchNorm1d(8),\n",
        "            # nn.Dropout(0.5),\n",
        "        )\n",
        "\n",
        "        self.full_layer = nn.Sequential(\n",
        "            # nn.Flatten(),\n",
        "            nn.Linear(120, 64),\n",
        "            nn.ReLU(),\n",
        "            # nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            # nn.Dropout(0.3),\n",
        "            nn.Linear(32, 128),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "        self.apply(self.init_weights)\n",
        "\n",
        "    def init_weights(self, m):\n",
        "        if isinstance(m, (nn.Conv1d, nn.Linear)):\n",
        "            init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.hiddenLayers(x)\n",
        "      x = x.view(x.size(0), -1)\n",
        "      x = self.full_layer(x)\n",
        "      return x\n",
        "\n",
        "# Create an instance of the model\n",
        "# model = SimpleAudioCNN()\n",
        "\n",
        "# # Print the model architecture\n",
        "# print(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0svT9943lnpM"
      },
      "outputs": [],
      "source": [
        "neural_network = OneD_CNN().to(device)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(neural_network.parameters(), lr=0.001)\n",
        "# learning_rate = 0.001\n",
        "# momentum = 0.9  # Optional: You can adjust the momentum term\n",
        "# optimizer = optim.SGD(neural_network.parameters(), lr=learning_rate, momentum=momentum)\n",
        "# for p in optimizer.param_groups:\n",
        "#   p['clip_grad_norm'] = 0.2\n",
        "# scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvneRQtElre4"
      },
      "outputs": [],
      "source": [
        "all_labels = []\n",
        "all_predicted = []\n",
        "all_predicted_prob = []\n",
        "def evaluation(data_loader, isTest=False):\n",
        "  neural_network.eval()\n",
        "  total, correct = 0, 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for data in data_loader:\n",
        "      inputs, labels = data\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "      outputs = neural_network(inputs)\n",
        "      _, prediction = torch.max(outputs.data, 1)\n",
        "      total = total + labels.size(0)\n",
        "      correct = correct + (prediction == labels).sum().item()\n",
        "      if isTest:\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        all_predicted.extend(prediction.cpu().numpy())\n",
        "        all_predicted_prob.extend(torch.nn.functional.softmax(outputs, dim=1)[:, 1].cpu().numpy())\n",
        "  return correct * 100 / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZXgjD9qdtj1"
      },
      "outputs": [],
      "source": [
        "wandb.init(project='DL_assignment2', name='Architecture 1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lx59uJLsluu3"
      },
      "outputs": [],
      "source": [
        "loss_epoch_arr = []\n",
        "training_accuracy_per_epoch = []\n",
        "validation_accuracy_per_epoch = []\n",
        "testing_accuracy_per_epoch = []\n",
        "epoch_counter = 1\n",
        "for i in range(2, 6):\n",
        "  custom_data_module = kfold(i)\n",
        "  for epoch in range(5):\n",
        "    neural_network.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in custom_data_module.train_dataloader():\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "      outputs = neural_network(inputs)\n",
        "      loss = loss_function(outputs, labels)\n",
        "\n",
        "      # lambda_reg = 0.001\n",
        "      # l2_regularization = 0.0\n",
        "      # for param in neural_network.parameters():\n",
        "      #     l2_regularization += torch.norm(param, p=2)\n",
        "      # loss += lambda_reg * l2_regularization\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      torch.nn.utils.clip_grad_norm_(neural_network.parameters(), max_norm=1)\n",
        "      optimizer.step()\n",
        "      running_loss += loss.item()\n",
        "    loss_epoch_arr.append(running_loss)\n",
        "\n",
        "    accuracy_training = evaluation(custom_data_module.train_dataloader())\n",
        "    accuracy_validation = evaluation(custom_data_module.val_dataloader())\n",
        "    accuracy_testing = evaluation(custom_data_module.test_dataloader())\n",
        "\n",
        "    training_accuracy_per_epoch.append(accuracy_training / 100)\n",
        "    validation_accuracy_per_epoch.append(accuracy_validation / 100)\n",
        "    testing_accuracy_per_epoch.append(accuracy_testing / 100)\n",
        "    # wandb.log({\"train_loss\": running_loss, \"train_accuracy\": accuracy_training}, step=epoch_counter)\n",
        "    # wandb.log({\"validation_accuracy\": accuracy_validation}, step=epoch_counter)\n",
        "    # wandb.log({\"test_accuracy\": accuracy_testing}, step=epoch_counter)\n",
        "    print(f\"Epoch: {epoch_counter}/{100}, Loss: {running_loss}, Test_Accuracy: {accuracy_testing}, Validation_Accuracy: {accuracy_validation}, Trainig_Accuracy: {accuracy_training}\")\n",
        "    # print()\n",
        "    epoch_counter += 1\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBZAtIemkxWR"
      },
      "outputs": [],
      "source": [
        "plt.plot(loss_epoch_arr, label=\"Loss\", color=\"purple\", linestyle='-', marker='o', markersize=8)\n",
        "plt.title(\"Loss per Epoch\", fontsize=16)\n",
        "plt.xlabel(\"Epochs\", fontsize=12)\n",
        "plt.ylabel(\"Loss\", fontsize=12)\n",
        "plt.grid(True, linestyle='--', alpha=1)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q71JFLQ0kyFE"
      },
      "outputs": [],
      "source": [
        "plt.plot(training_accuracy_per_epoch, label=\"Accuracy\", color=\"orange\", linestyle='-', marker='o', markersize=8)\n",
        "plt.title(\"Training Accuracy per Epoch\", fontsize=16)\n",
        "plt.xlabel(\"Epochs\", fontsize=12)\n",
        "plt.ylabel(\"Accuracy\", fontsize=12)\n",
        "plt.grid(True, linestyle='--', alpha=1)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSRLs4Xqk3Ee"
      },
      "outputs": [],
      "source": [
        "plt.plot(validation_accuracy_per_epoch, label=\"Accuracy\", color=\"orange\", linestyle='-', marker='o', markersize=8)\n",
        "plt.title(\"Training Accuracy per Epoch\", fontsize=16)\n",
        "plt.xlabel(\"Epochs\", fontsize=12)\n",
        "plt.ylabel(\"Accuracy\", fontsize=12)\n",
        "plt.grid(True, linestyle='--', alpha=1)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSFK0izvk1Jj"
      },
      "outputs": [],
      "source": [
        "plt.plot(testing_accuracy_per_epoch, label=\"Accuracy\", color=\"orange\", linestyle='-', marker='o', markersize=8)\n",
        "plt.title(\"Testing Accuracy per Epoch\", fontsize=16)\n",
        "plt.xlabel(\"Epochs\", fontsize=12)\n",
        "plt.ylabel(\"Accuracy\", fontsize=12)\n",
        "plt.grid(True, linestyle='--', alpha=1)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W40-tlFTozeg"
      },
      "outputs": [],
      "source": [
        "evaluation(custom_data_module.test_dataloader(), isTest=True)\n",
        "conf_mat = confusion_matrix(all_labels, all_predicted)\n",
        "plt.figure(figsize=(8, 6))\n",
        "# plt.imshow(conf_mat, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='summer', xticklabels=range(10), yticklabels=range(10))\n",
        "plt.title('Confusion Matrix')\n",
        "# plt.colorbar()\n",
        "# classes = ['Class 0', 'Class 1']  # Modify based on your class labels\n",
        "# tick_marks = np.arange(len(classes))\n",
        "# plt.xticks(tick_marks, classes)\n",
        "# plt.yticks(tick_marks, classes)\n",
        "\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqG6OCJqs6Co"
      },
      "outputs": [],
      "source": [
        "y_true = np.array(all_labels)\n",
        "y_pred = np.array(all_predicted)\n",
        "y_pred_prob = np.array(all_predicted_prob)\n",
        "y_true_one_hot = label_binarize(y_true, classes=np.unique(y_true))\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "print(f'Weighted F1 Score: {f1}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfeLkyFTmSbm"
      },
      "outputs": [],
      "source": [
        "all_labels1 = np.array(all_labels)\n",
        "all_predicted_prob1 = np.array(all_predicted_prob)\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(len(np.unique(all_labels))):\n",
        "    # Use the true labels for the binary comparison\n",
        "    fpr[i], tpr[i], _ = roc_curve((all_labels1 == i).astype(int), all_predicted_prob1)\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Plot ROC curve for each class\n",
        "plt.figure(figsize=(8, 6))\n",
        "for i in range(len(np.unique(all_labels1))):\n",
        "    plt.plot(fpr[i], tpr[i], label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
        "plt.xlabel('False Positive Rate (FPR)')\n",
        "plt.ylabel('True Positive Rate (TPR)')\n",
        "plt.title('AUC-ROC Curve for Test Set (Multi-Class)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2zg0jRQQt6h"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "  def __init__(self, d_model, seq_length, dropout = 0.1):\n",
        "    super().__init__()\n",
        "    self.d_model = d_model\n",
        "    self.seq_length = seq_length\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    self.positional_encoding_vector = torch.zeros(seq_length, d_model) #(seq_length * d_model)\n",
        "    position = torch.arange(0, seq_length).unsqueeze(1) #(seq_length * 1) adds a new dimension\n",
        "    div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "    #torch.arange(start, end, step) creates 1d array from start to end - 1 with step\n",
        "    #example - torch.arange(0, 10, 2) -> [0, 2,4,6,8] -> basically (1 * end-start//step) matrix\n",
        "\n",
        "    self.positional_encoding_vector[:, 0::2] = torch.sin(position * div_term)\n",
        "    #position_encoding_vector is a seq_length * d_model vector it means it has se_length rows and d_model columns so [:, 0::2] will filter out\n",
        "    #each even index (start from 0 and goes to 2, 4,6....) column for each row and assigns torch.sin(position * div_term) this term\n",
        "\n",
        "    self.positional_encoding_vector[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "    self.positional_encoding_vector = self.positional_encoding_vector.unsqueeze(0)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # print(\"positional1\", x.shape)\n",
        "    x = x + (self.positional_encoding_vector[:, :x.shape[1], :]).requires_grad_(False)\n",
        "    # print(\"positional2\", x.shape)\n",
        "    x = self.dropout(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZekVLh22cpOm"
      },
      "outputs": [],
      "source": [
        "class LayerNormalization(nn.Module):\n",
        "  def __init__(self, epsilon = 10**-6):\n",
        "    super().__init__()\n",
        "    self.epsilon = epsilon # used to avoid division by zero\n",
        "    self.alpha = nn.Parameter(torch.ones(1))\n",
        "    self.bias = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "  def forward(self, x):\n",
        "    # print(\"inside LayerNormalization - x shape:\", x.shape)\n",
        "    mean = x.mean(dim = -1, keepdim=True)\n",
        "    # print(\"inside LayerNormalization - mean:\", mean)\n",
        "    std = x.std(dim = -1, keepdim=True)\n",
        "    # print(\"inside LayerNormalization - mean:\", mean)\n",
        "    x = self.alpha * (x - mean) / (std + self.epsilon) + self.bias\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HO3Y9VtjfpEw"
      },
      "outputs": [],
      "source": [
        "class MLPBlock(nn.Module):\n",
        "  def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "    super().__init__()\n",
        "    self.linear1 = nn.Linear(d_model, d_ff)\n",
        "    self.relu1 = nn.ReLU()\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.linear2 = nn.Linear(d_ff, d_model)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # print(10)\n",
        "    x = self.linear1(x)\n",
        "    # print(11)\n",
        "    x = self.relu1(x)\n",
        "    x = self.dropout(x)\n",
        "    # print(12)\n",
        "    x = self.linear2(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afrGqaQRqn_h"
      },
      "outputs": [],
      "source": [
        "class ResidualConnection(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.norm = LayerNormalization()\n",
        "\n",
        "  def forward(self, x, sublayer):\n",
        "    # print(\"inside ResidualConnection - x shape:\", x.shape)\n",
        "    normalized_x = self.norm(x)\n",
        "    # print(\"inside ResidualConnection - normalized_x shape:\", normalized_x.shape)\n",
        "    output_of_sublayer = sublayer(normalized_x)\n",
        "    # print(\"inside ResidualConnection - output_of_sublayer shape:\", output_of_sublayer.shape)\n",
        "    result = x + output_of_sublayer\n",
        "    # print(\"inside ResidualConnection - result shape:\", result.shape)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwpqaBNPhokw"
      },
      "outputs": [],
      "source": [
        "class MultiHeadSelfAttentionBlock(nn.Module):\n",
        "  def __init__(self, d_model, h, dropout=0.1):\n",
        "    super().__init__()\n",
        "    self.d_model = d_model\n",
        "    self.h = h\n",
        "    assert d_model % h == 0, \"d_model is not divisible by h\"\n",
        "\n",
        "    self.d_k = self.d_model // self.h\n",
        "    self.w_q = nn.Linear(d_model, d_model)\n",
        "    self.w_k = nn.Linear(d_model, d_model)\n",
        "    self.w_v = nn.Linear(d_model, d_model)\n",
        "\n",
        "    self.w_o = nn.Linear(d_model, d_model)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  @staticmethod\n",
        "  def attention(query, key, value):\n",
        "    d_k = query.shape[-1]\n",
        "    attention_scores = (query @ key.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "    attention_scores = attention_scores.softmax(dim = -1)\n",
        "    attention_matrix = (attention_scores @ value)\n",
        "    return attention_matrix, attention_scores\n",
        "\n",
        "  def forward(self, q, k, v):\n",
        "    # print(5, q.shape)\n",
        "    query = self.w_q(q)\n",
        "    # print(51, k.shape)\n",
        "    key = self.w_k(k)\n",
        "    # print(52, v.shape)\n",
        "    value = self.w_v(v)\n",
        "    # print(6)\n",
        "    query = query.view(query.shape[0], query.shape[1],self.h, self.d_k).transpose(1, 2)\n",
        "    key = key.view(key.shape[0], key.shape[1],self.h, self.d_k).transpose(1, 2)\n",
        "    value = value.view(value.shape[0], value.shape[1],self.h, self.d_k).transpose(1, 2)\n",
        "    # print(7)\n",
        "    x, self.attention_scores = MultiHeadSelfAttentionBlock.attention(query, key, value)\n",
        "    # print(8)\n",
        "    x = x.transpose(1, 2).contiguous().view(x.shape[0], -1, self.h * self.d_k)\n",
        "    #The use of contiguous is important when you want to use the view method on a tensor that may have a non-contiguous memory layout\n",
        "    # print(9)\n",
        "    x = self.w_o(x)\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXpi2g21JqRR"
      },
      "outputs": [],
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "  def __init__(self, d_model, h, dropout=0.1, d_ff=2048):\n",
        "    super().__init__()\n",
        "    self.positional_encoding = PositionalEncoding(d_model, seq_length=512)\n",
        "    self.multi_head_self_attention_block = MultiHeadSelfAttentionBlock(d_model, h, dropout)\n",
        "    self.feed_forward_block = MLPBlock(d_model, d_ff, dropout)\n",
        "    # self.residual_connection = nn.ModuleList([\n",
        "    #   ResidualConnection(self.multi_head_self_attention_block, d_model),\n",
        "    #   ResidualConnection(self.feed_forward_block, d_model)\n",
        "    # ])\n",
        "    self.residual_connection = nn.ModuleList([ResidualConnection() for _ in range(2)])\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x = self.resresidual_connection[0](x, lambda x: self.multi_head_self_attention_block(x, x, x))\n",
        "    # x = self.resresidual_connection[1](x, self.feed_forward_block)\n",
        "    # print(1, x.shape)\n",
        "    x = self.positional_encoding(x)\n",
        "    # print(2, x.shape)\n",
        "    # attention_output = self.multi_head_self_attention_block(x, x, x)\n",
        "    x = self.residual_connection[0](x, lambda x: self.multi_head_self_attention_block(x, x, x))\n",
        "    # print(3)\n",
        "    x = self.residual_connection[1](x, self.feed_forward_block)\n",
        "    # print(4)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXVSE4HutLI5"
      },
      "outputs": [],
      "source": [
        "# class EncoderBlock(nn.Module):\n",
        "#   def __init__(self, features, multi_head_self_attention_block, feed_forward_block):\n",
        "#     super().__init__()\n",
        "#     self.multi_head_self_attention_block = multi_head_self_attention_block\n",
        "#     self.feed_forward_block = feed_forward_block\n",
        "#     self.residual_connection = nn.ModuleList([ResidualConnection(features) for _ in range(2)])\n",
        "\n",
        "#   def forward(self, x):\n",
        "#     # x = self.resresidual_connection[0](x, lambda x: self.multi_head_self_attention_block(x, x, x))\n",
        "#     # x = self.resresidual_connection[1](x, self.feed_forward_block)\n",
        "#     attention_output = self.multi_head_self_attention_block(x, x, x)\n",
        "#     x = self.resresidual_connection[0](x, attention_output)\n",
        "#     x = self.resresidual_connection[1](x, self.feed_forward_block)\n",
        "#     return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5143YWXTHhN"
      },
      "outputs": [],
      "source": [
        "from lightning.pytorch.loggers import WandbLogger\n",
        "wandb_logger = WandbLogger()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlrisXC8QtyU"
      },
      "outputs": [],
      "source": [
        "class CNNTransformerClassifier(pl.LightningModule):\n",
        "    def __init__(self, num_classes, d_model, cnn_model, n_heads):\n",
        "        super(CNNTransformerClassifier, self).__init__()\n",
        "\n",
        "        # Base CNN model\n",
        "        self.cnn_model = cnn_model\n",
        "        self.maxpool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Transformer encoder blocks with varying number of heads\n",
        "        self.transformer_blocks = nn.ModuleList([\n",
        "            EncoderBlock(d_model, n_heads) for _ in range(3)\n",
        "        ])\n",
        "\n",
        "        # MLP head for classification\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.Linear(d_model, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, num_classes)\n",
        "        )\n",
        "\n",
        "        # self.f1_score = MulticlassF1Score(num_classes=num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = self.hiddenLayers(x)\n",
        "        # x = x.view(x.size(0), -1)\n",
        "        # x = self.full_layer(x)\n",
        "        # Base CNN\n",
        "        # print('m',x.shape)\n",
        "        x_cnn = self.cnn_model.hiddenLayers(x)  # Extract output from the second last layer\n",
        "        x_cnn = x_cnn.view(x_cnn.size(0), -1)  # Extract output from the second last layer\n",
        "        x = self.cnn_model.full_layer[:-2](x_cnn)\n",
        "        # print('aa', x.shape)\n",
        "        # x = self.maxpool(x_cnn)\n",
        "        # print('a', x.shape)\n",
        "        # x_cnn = x_cnn.view(x_cnn.size(0), -1)\n",
        "        # print('b',x.shape)\n",
        "        # x = torch.mean(x, dim=-2)\n",
        "        # Transformer encoder blocks with varying number of heads\n",
        "        cls_token = torch.zeros(x.size(0), 1, x.size(1)).to(x.device)\n",
        "        x_with_cls = torch.cat([cls_token, x.unsqueeze(1)], dim=1)\n",
        "        for transformer_block in self.transformer_blocks:\n",
        "            # print(\"asd\", x_with_cls.shape)\n",
        "            x_with_cls  = transformer_block(x_with_cls)\n",
        "            # print(\"asds\")\n",
        "        #     print(f'c{i}', x_cnn.shape)\n",
        "        # print('c',x.shape)\n",
        "        x_with_cls = x_with_cls[:, 0, :]\n",
        "        # MLP head for classification\n",
        "        x = self.mlp_head(x_with_cls)\n",
        "        # print('d',x.shape)\n",
        "        # print()\n",
        "\n",
        "        return x\n",
        "\n",
        "    # def training_step(self, batch, batch_idx):\n",
        "    #   inputs, labels = batch\n",
        "    #   outputs = self(inputs)\n",
        "    #   loss = F.cross_entropy(outputs, labels)\n",
        "    #   acc = Accuracy(task='multiclass', num_classes=num_classes)(outputs, labels)\n",
        "    #   self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
        "    #   self.log('train_acc', acc, on_step=True, on_epoch=True, prog_bar=True)\n",
        "    #   return loss\n",
        "\n",
        "    # def validation_step(self, batch, batch_idx):\n",
        "    #   inputs, labels = batch\n",
        "    #   outputs = self(inputs)\n",
        "    #   loss = F.cross_entropy(outputs, labels)\n",
        "    #   acc = Accuracy(task='multiclass', num_classes=num_classes)(outputs, labels)\n",
        "    #   self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
        "    #   self.log('val_acc', acc, on_step=True, on_epoch=True, prog_bar=True)\n",
        "    #   return loss\n",
        "\n",
        "    # def test_step(self, batch, batch_idx):\n",
        "    #   inputs, labels = batch\n",
        "    #   outputs = self(inputs)\n",
        "    #   loss = F.cross_entropy(outputs, labels)\n",
        "    #   acc = Accuracy(task='multiclass', num_classes=num_classes)(outputs, labels)\n",
        "    #   confusion_matrix = ConfusionMatrix(task='multiclass', num_classes=num_classes)(outputs, labels)\n",
        "    #   f1 = MulticlassF1Score(num_classes=num_classes, average=None)(outputs, labels)\n",
        "    #   # fig_, ax_ = f1.plot()\n",
        "    #   auc_roc = MulticlassAUROC(num_classes=num_classes, average=\"macro\", thresholds=None)(outputs, labels)\n",
        "    #   # fig_, ax_ = auc_roc.plot()\n",
        "\n",
        "    #   self.log('test_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
        "    #   self.log('test_acc', acc, on_step=True, on_epoch=True, prog_bar=True)\n",
        "    #   self.log('test_confusion_matrix', confusion_matrix, on_step=True, on_epoch=True, prog_bar=True)\n",
        "    #   self.log('test_f1', f1, on_step=True, on_epoch=True, prog_bar=True)\n",
        "    #   self.log('test_auc_roc', auc_roc, on_step=True, on_epoch=True, prog_bar=True)\n",
        "\n",
        "    #   return outputs, labels\n",
        "\n",
        "    # def configure_optimizers(self):\n",
        "    #   return optim.Adam(self.parameters(), lr = 0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNxD1cUDQSx2"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wF9GydYRe8my"
      },
      "outputs": [],
      "source": [
        "# num_classes = 10\n",
        "# d_model = 128\n",
        "# cnn_out_channels = 64\n",
        "# # transformer_heads_list = [1,2,4]\n",
        "# transformer_heads_list = [4]\n",
        "# learning_rate = 0.001\n",
        "# num_epochs = 1\n",
        "# cnn_model = OneD_CNN()\n",
        "\n",
        "# for num_heads in transformer_heads_list:\n",
        "#   model = CNNTransformerClassifier(num_classes, d_model, cnn_model, n_heads=num_heads)\n",
        "\n",
        "#   # for folds in range(2, 6):\n",
        "#   for folds in range(2, 3):\n",
        "#     custom_data_module = kfold(folds)\n",
        "#     trainer = pl.Trainer(max_epochs=num_epochs, logger=wandb_logger)\n",
        "#     trainer.fit(model, custom_data_module.train_dataloader(), custom_data_module.val_dataloader())\n",
        "#     trainer.test(model, custom_data_module.test_dataloader())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "d_model = 128\n",
        "cnn_out_channels = 64\n",
        "transformer_heads_list = [1,2,4]\n",
        "# transformer_heads_list = [4]\n",
        "learning_rate = 0.001\n",
        "num_epochs = 100"
      ],
      "metadata": {
        "id": "j1evmiRBBE5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TudaEJXndHqb"
      },
      "outputs": [],
      "source": [
        "all_labels = []\n",
        "all_predicted = []\n",
        "all_predicted_prob = []\n",
        "def evaluation2(model, data_loader, isTest=False):\n",
        "  model.eval()\n",
        "  total, correct = 0, 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for data in data_loader:\n",
        "      inputs, labels = data\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "      outputs = model(inputs)\n",
        "      _, prediction = torch.max(outputs.data, 1)\n",
        "      total = total + labels.size(0)\n",
        "      correct = correct + (prediction == labels).sum().item()\n",
        "      if isTest:\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        all_predicted.extend(prediction.cpu().numpy())\n",
        "        all_predicted_prob.extend(torch.nn.functional.softmax(outputs, dim=1)[:, 1].cpu().numpy())\n",
        "  return correct * 100 / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcijO8teeG60"
      },
      "outputs": [],
      "source": [
        "wandb.init(project='DL_assignment2', name='Architecture 2')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_epoch_arr = []\n",
        "training_accuracy_per_epoch = []\n",
        "validation_accuracy_per_epoch = []\n",
        "testing_accuracy_per_epoch = []\n",
        "epoch_counter = 1"
      ],
      "metadata": {
        "id": "MxzUKXYsBCMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjcXp1EZQtvu"
      },
      "outputs": [],
      "source": [
        "# Instantiate the base CNN model\n",
        "cnn_model = OneD_CNN()\n",
        "\n",
        "# Training loop\n",
        "for num_heads in transformer_heads_list:\n",
        "  # Instantiate the CNNTransformerClassifier\n",
        "  model = CNNTransformerClassifier(num_classes, d_model, cnn_model, n_heads=num_heads)\n",
        "  # print(model)\n",
        "\n",
        "  # Loss function and optimizer\n",
        "  loss_function = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  # Device configuration (use GPU if available)\n",
        "  model = model.to(device)\n",
        "\n",
        "  for folds in range(2, 6):\n",
        "  # for folds in range(2, 3):\n",
        "    custom_data_module = kfold(folds)\n",
        "    for epoch in range(num_epochs):\n",
        "      model.train()  # Set the model to training mode\n",
        "      running_loss = 0.0\n",
        "      for inputs, labels in custom_data_module.train_dataloader():\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_function(outputs, labels)\n",
        "\n",
        "        # lambda_reg = 0.001\n",
        "        # l2_regularization = 0.0\n",
        "        # for param in neural_network.parameters():\n",
        "        #     l2_regularization += torch.norm(param, p=2)\n",
        "        # loss += lambda_reg * l2_regularization\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "      loss_epoch_arr.append(running_loss)\n",
        "\n",
        "      accuracy_training = evaluation2(model, custom_data_module.train_dataloader())\n",
        "      accuracy_validation = evaluation2(model, custom_data_module.val_dataloader())\n",
        "      accuracy_testing = evaluation2(model, custom_data_module.test_dataloader())\n",
        "\n",
        "      training_accuracy_per_epoch.append(accuracy_training / 100)\n",
        "      validation_accuracy_per_epoch.append(accuracy_validation / 100)\n",
        "      testing_accuracy_per_epoch.append(accuracy_testing / 100)\n",
        "      wandb.log({\"train_loss\": running_loss, \"train_accuracy\": accuracy_training}, step=epoch_counter)\n",
        "      wandb.log({\"validation_accuracy\": accuracy_validation}, step=epoch_counter)\n",
        "      wandb.log({\"test_accuracy\": accuracy_testing}, step=epoch_counter)\n",
        "      print(f\"Epoch: {epoch_counter}/{100}, Loss: {running_loss}, Test_Accuracy: {accuracy_testing}, Validation_Accuracy: {accuracy_validation}, Trainig_Accuracy: {accuracy_training}\")\n",
        "      # print()\n",
        "      epoch_counter += 1\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CGVSoQuQttH"
      },
      "outputs": [],
      "source": [
        "evaluation2(model, custom_data_module.test_dataloader(), isTest=True)\n",
        "conf_mat = confusion_matrix(all_labels, all_predicted)\n",
        "plt.figure(figsize=(8, 6))\n",
        "# plt.imshow(conf_mat, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='summer', xticklabels=range(10), yticklabels=range(10))\n",
        "plt.title('Confusion Matrix')\n",
        "# plt.colorbar()\n",
        "# classes = ['Class 0', 'Class 1']  # Modify based on your class labels\n",
        "# tick_marks = np.arange(len(classes))\n",
        "# plt.xticks(tick_marks, classes)\n",
        "# plt.yticks(tick_marks, classes)\n",
        "\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-22T16:31:25.410717Z",
          "iopub.status.busy": "2024-02-22T16:31:25.410298Z",
          "iopub.status.idle": "2024-02-22T16:31:39.339243Z",
          "shell.execute_reply": "2024-02-22T16:31:39.338271Z",
          "shell.execute_reply.started": "2024-02-22T16:31:25.410688Z"
        },
        "id": "Qlz7bsQ9_BgB"
      },
      "outputs": [],
      "source": [
        "!pip install optuna\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-22T16:41:20.726800Z",
          "iopub.status.busy": "2024-02-22T16:41:20.725847Z",
          "iopub.status.idle": "2024-02-22T16:59:13.532610Z",
          "shell.execute_reply": "2024-02-22T16:59:13.531529Z",
          "shell.execute_reply.started": "2024-02-22T16:41:20.726760Z"
        },
        "id": "eeel20j__BgB"
      },
      "outputs": [],
      "source": [
        "max_epochs = 20\n",
        "custom_data_module = kfold(4)\n",
        "def hyperparameters(trial):\n",
        "  learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n",
        "  # batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])\n",
        "  weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-3, log=True)\n",
        "  dropout_prob = trial.suggest_float('dropout_prob', 0.0, 0.5)\n",
        "  # momentum = trial.suggest_float('momentum', 0.0, 0.9)\n",
        "  step_size = trial.suggest_int('step_size', 1, 10)\n",
        "  gamma = trial.suggest_float('gamma', 0.1, 0.9)\n",
        "  beta1 = trial.suggest_float('beta1', 0.1, 0.9)\n",
        "\n",
        "\n",
        "  loss_function = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(beta1, 0.999), weight_decay=weight_decay)\n",
        "  scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "\n",
        "  loss_epoch_arr = []\n",
        "  accuracy_per_epoch = []\n",
        "  for epoch in range(max_epochs):\n",
        "    for i, data in enumerate(custom_data_module.train_dataloader()):\n",
        "      inputs, labels = data\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      outputs = model(inputs)\n",
        "      loss = loss_function(outputs, labels)\n",
        "      # l2_regularization = 0.0\n",
        "      # for param in neural_network_4Class.parameters():\n",
        "      #   l2_regularization += torch.norm(param, 2)\n",
        "      # loss += 1e-4 * l2_regularization\n",
        "\n",
        "      lambda_reg = 1e-5\n",
        "      l2_regularization = 0.0\n",
        "      for param in model.parameters():\n",
        "        l2_regularization += torch.sum(param**2)\n",
        "      l2_regularization = torch.sqrt(l2_regularization)\n",
        "      loss += lambda_reg * l2_regularization\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    loss_epoch_arr.append(loss.item())\n",
        "    scheduler.step()\n",
        "    accuracy, _, _, _, _ = evaluation2(model, custom_data_module.train_dataloader())\n",
        "    accuracy_test, _, _, _, _ = evaluation2(model, custom_data_module.test_dataloader())\n",
        "    accuracy_per_epoch.append(accuracy / 100)\n",
        "    # print(f\"Epoch: {epoch+1}/{max_epochs}, Loss: {loss}, Test_Accuracy: {evaluation2(test_loader)}, Trainig_Accuracy: {evaluation2(train_loader)}\")\n",
        "    print(f\"Epoch: {epoch+1}/{max_epochs}, Loss: {loss}, Test_Accuracy: {accuracy_test}, Trainig_Accuracy: {accuracy}\")\n",
        "    accuracy, _, _, _, _ = evaluation2(model,custom_data_module.test_dataloader())\n",
        "  return loss_epoch_arr[-1]\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(hyperparameters, n_trials=10)\n",
        "best_params = study.best_params\n",
        "best_learning_rate = best_params['learning_rate']\n",
        "# best_batch_size = best_params['batch_size']\n",
        "best_weight_decay = best_params['weight_decay']\n",
        "best_dropout_prob = best_params['dropout_prob']\n",
        "# best_momentum = best_params['momentum']\n",
        "best_step_size = best_params['step_size']\n",
        "best_gamma = best_params['gamma']\n",
        "best_beta1 = best_params['beta1']\n",
        "\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(\"Learning Rate:\", best_learning_rate)\n",
        "# print(\"Batch Size:\", best_batch_size)\n",
        "print(\"Weight Decay:\", best_weight_decay)\n",
        "print(\"Dropout Probability:\", best_dropout_prob)\n",
        "# print(\"Momentum:\", best_momentum)\n",
        "print(\"Step Size for LR Scheduler:\", best_step_size)\n",
        "print(\"Gamma for LR Scheduler:\", best_gamma)\n",
        "print(\"Beta1 (Momentum in Adam):\", best_beta1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 4478644,
          "sourceId": 7677353,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30646,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}